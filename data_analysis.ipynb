{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c94cdf50-ddff-4d23-96f5-55fbd9a25eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50880b3e-846d-4b0c-89ce-28b131a5ea66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Company  Revenue  Revenue_Normalized\n",
      "0       A    25000            0.000000\n",
      "1       B    47000            0.785714\n",
      "2       C    53000            1.000000\n",
      "3       D    32000            0.250000\n"
     ]
    }
   ],
   "source": [
    "# Exercise 1: DataFrame Manipulation\n",
    "# Given the following DataFrame, normalize the 'Revenue' \n",
    "# column so that all values are between 0 and 1\n",
    "# NewValue = (((OldValue - OldMin) * (NewMax - NewMin)) / (OldMax - OldMin)) + NewMin\n",
    "# Here NewMin = 0 and NewMax = 1\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'Company': ['A', 'B', 'C', 'D'],\n",
    "    'Revenue': [25000, 47000, 53000, 32000]\n",
    "})\n",
    "# OldMin = df.Revenue.min()\n",
    "OldMin = df['Revenue'].min() # method 1\n",
    "OldMax = pd.Series.max(df.Revenue) # method 2\n",
    "df['Revenue_Normalized'] = [(((OldValue - OldMin) * (1 - 0)) / (OldMax - OldMin)) + 0 for OldValue in df['Revenue']]\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a59688fc-955c-495d-bb01-ba3b796cf1b4",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "Missing parentheses in call to 'print'. Did you mean print(...)? (3073746064.py, line 8)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mprint i\u001b[39m\n    ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m Missing parentheses in call to 'print'. Did you mean print(...)?\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    'Company': ['A', 'B', 'C', 'D'],\n",
    "    'Revenue': [25000, 47000, 53000, 32000]\n",
    "})\n",
    "# OldMin = df.Revenue.min()\n",
    "for i in df.columns:\n",
    "    if i.type == int:\n",
    "        print i\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3caa3660-4d4e-450a-925f-5dce294c4032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company\n",
      "A    55000\n",
      "B    83000\n",
      "Name: Revenue, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Exercise 2: Custom Aggregations\n",
    "# Given the DataFrame below, calculate the sum of Revenue for each company.\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'Company': ['A', 'B', 'A', 'B', 'A'],\n",
    "    'Revenue': [20000, 35000, 23000, 48000, 12000]\n",
    "})\n",
    "gk = df.groupby('Company')\n",
    "result = gk['Revenue'].aggregate('sum')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ae52c66-9d00-4267-8638-2462fe4115c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID     Name      City\n",
      "0   1    Alice       NaN\n",
      "1   2      Bob  New York\n",
      "2   3  Charlie     Paris\n",
      "3   4      NaN     Tokyo\n"
     ]
    }
   ],
   "source": [
    "# Exercise 3: Merge Two DataFrames Using Different Join Types\n",
    "# Perform an outer join between two DataFrames.\n",
    "df1 = pd.DataFrame({'ID': [1, 2, 3], 'Name': ['Alice', 'Bob', 'Charlie']})\n",
    "df2 = pd.DataFrame({'ID': [2, 3, 4], 'City': ['New York', 'Paris', 'Tokyo']})\n",
    "res  = pd.merge(df1, df2, on='ID', how='outer')\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4676d8be-ac5e-45cd-8fdb-4c309185e70b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "customer_id\n",
      "1   2025-04-01\n",
      "2   2025-04-03\n",
      "3   2025-04-03\n",
      "Name: date, dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "# Exercise 4: Identifying and Removing Duplicate Entries Efficiently\n",
    "# while retaining the last transaction for each customer\n",
    "data = {\n",
    "    'customer_id': [1, 2, 2, 3, 3, 3],\n",
    "    'transaction_id': [101, 102, 103, 104, 105, 106],\n",
    "    'date': pd.to_datetime(['2025-04-01', '2025-04-02', '2025-04-03', '2025-04-01', '2025-04-02', '2025-04-03'])\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "df1 = df.groupby('customer_id')\n",
    "result = df1['date'].aggregate('max')\n",
    "# df2 = df.groupby('customer_id')['date'].aggregate('max')\n",
    "# df3 = df.groupby('customer_id')['date'].max()\n",
    "# df4 = df.groupby('customer_id').aggregate({'date': 'max'})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5d4b122-9266-4ee4-afe0-bb1a1f43cc27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   customer_id  transaction_id       date\n",
      "0            1             101 2025-04-01\n",
      "2            2             103 2025-04-03\n",
      "5            3             106 2025-04-03\n"
     ]
    }
   ],
   "source": [
    "# Method 2:\n",
    "df_cleaned = df.sort_values(by=['date']).drop_duplicates(subset=['customer_id'], keep='last')\n",
    "print(df_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "367a5963-4157-4f3e-9bb9-d55d87decf92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date  Day     Month  Year  Customer_Age       Age_Group  \\\n",
      "0  2013-11-26   26  November  2013            19     Youth (<25)   \n",
      "1  2015-11-26   26  November  2015            19     Youth (<25)   \n",
      "2  2014-03-23   23     March  2014            49  Adults (35-64)   \n",
      "3  2016-03-23   23     March  2016            49  Adults (35-64)   \n",
      "4  2014-05-15   15       May  2014            47  Adults (35-64)   \n",
      "\n",
      "  Customer_Gender    Country             State Product_Category Sub_Category  \\\n",
      "0               M     Canada  British Columbia      Accessories   Bike Racks   \n",
      "1               M     Canada  British Columbia      Accessories   Bike Racks   \n",
      "2               M  Australia   New South Wales      Accessories   Bike Racks   \n",
      "3               M  Australia   New South Wales      Accessories   Bike Racks   \n",
      "4               F  Australia   New South Wales      Accessories   Bike Racks   \n",
      "\n",
      "               Product  Order_Quantity  Unit_Cost  Unit_Price  Profit  Cost  \\\n",
      "0  Hitch Rack - 4-Bike               8         45         120     590   360   \n",
      "1  Hitch Rack - 4-Bike               8         45         120     590   360   \n",
      "2  Hitch Rack - 4-Bike              23         45         120    1366  1035   \n",
      "3  Hitch Rack - 4-Bike              20         45         120    1188   900   \n",
      "4  Hitch Rack - 4-Bike               4         45         120     238   180   \n",
      "\n",
      "   Revenue  \n",
      "0      950  \n",
      "1      950  \n",
      "2     2401  \n",
      "3     2088  \n",
      "4      418  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 113036 entries, 0 to 113035\n",
      "Data columns (total 18 columns):\n",
      " #   Column            Non-Null Count   Dtype \n",
      "---  ------            --------------   ----- \n",
      " 0   Date              113036 non-null  object\n",
      " 1   Day               113036 non-null  int64 \n",
      " 2   Month             113036 non-null  object\n",
      " 3   Year              113036 non-null  int64 \n",
      " 4   Customer_Age      113036 non-null  int64 \n",
      " 5   Age_Group         113036 non-null  object\n",
      " 6   Customer_Gender   113036 non-null  object\n",
      " 7   Country           113036 non-null  object\n",
      " 8   State             113036 non-null  object\n",
      " 9   Product_Category  113036 non-null  object\n",
      " 10  Sub_Category      113036 non-null  object\n",
      " 11  Product           113036 non-null  object\n",
      " 12  Order_Quantity    113036 non-null  int64 \n",
      " 13  Unit_Cost         113036 non-null  int64 \n",
      " 14  Unit_Price        113036 non-null  int64 \n",
      " 15  Profit            113036 non-null  int64 \n",
      " 16  Cost              113036 non-null  int64 \n",
      " 17  Revenue           113036 non-null  int64 \n",
      "dtypes: int64(9), object(9)\n",
      "memory usage: 15.5+ MB\n",
      "None\n",
      "Missing values before cleaning:\n",
      "\n",
      "Date                0\n",
      "Day                 0\n",
      "Month               0\n",
      "Year                0\n",
      "Customer_Age        0\n",
      "Age_Group           0\n",
      "Customer_Gender     0\n",
      "Country             0\n",
      "State               0\n",
      "Product_Category    0\n",
      "Sub_Category        0\n",
      "Product             0\n",
      "Order_Quantity      0\n",
      "Unit_Cost           0\n",
      "Unit_Price          0\n",
      "Profit              0\n",
      "Cost                0\n",
      "Revenue             0\n",
      "dtype: int64\n",
      "Missing values after cleaning up:\n",
      "\n",
      "Date                0\n",
      "Day                 0\n",
      "Month               0\n",
      "Year                0\n",
      "Customer_Age        0\n",
      "Age_Group           0\n",
      "Customer_Gender     0\n",
      "Country             0\n",
      "State               0\n",
      "Product_Category    0\n",
      "Sub_Category        0\n",
      "Product             0\n",
      "Order_Quantity      0\n",
      "Unit_Cost           0\n",
      "Unit_Price          0\n",
      "Profit              0\n",
      "Cost                0\n",
      "Revenue             0\n",
      "dtype: int64\n",
      "Total Revenue: $95176318.00\n",
      "Top 10 Best Selling Products:\n",
      "Product\n",
      "Road-150 Red, 62           4261398\n",
      "Mountain-200 Black, 38     3768390\n",
      "Road-150 Red, 56           3542220\n",
      "Road-150 Red, 52           3506440\n",
      "Mountain-200 Silver, 38    3426640\n",
      "Road-150 Red, 48           3406256\n",
      "Mountain-200 Silver, 42    3389520\n",
      "Mountain-200 Black, 46     3095955\n",
      "Mountain-200 Black, 42     2942190\n",
      "Mountain-200 Silver, 46    2665680\n",
      "Name: revenue, dtype: int64\n",
      "Average daily sales revenue: $50518.22\n"
     ]
    }
   ],
   "source": [
    "# Exercise 5: Handeling Missing Data with Advanced Imputation Techniques\n",
    "# Scenario: You have a CSV file named sales_data.csv containing daily sales records.\n",
    "# Your task is to read the file, clean the data, and generate insights such as total revenue, \n",
    "# top-selling products and average daily sales.\n",
    "# Data Cleaning: Handling missing values to ensure accuracy.\n",
    "# Revenue Calculation: Computing total sales value per transaction.\n",
    "# Best Seller Identification: Grouping and summarizing top-performing products.\n",
    "# Trend Analysis: Determining the daily sales trend.\n",
    "\n",
    "df_original = pd.read_csv(\"Datasets/sales_data.csv\")\n",
    "df = df_original.copy()\n",
    "\n",
    "print(df.head())\n",
    "print(df.info()) # Check for missing values and data types\n",
    "\n",
    "print(\"Missing values before cleaning:\\n\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "df.fillna(df.mean(numeric_only=True), inplace=True)\n",
    "\n",
    "# Fill missing values in categorical (object) columns with the mode (most frequent value)\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == 'object' and df[col].isnull().any():  # Make sure there's at least one missing value\n",
    "        df[col] = df[col].fillna(df[col].mode()[0])\n",
    "\n",
    "# for col in df.select_dtypes(include='object').columns:\n",
    "#     if df[col].isnull().any():\n",
    "#         df[col].fillna(df[col].mode()[0], inplace=True)\n",
    "\n",
    "print(\"Missing values after cleaning up:\\n\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Calculate revenue for each row: quantity * price\n",
    "# Make sure 'Order_Quantity' and 'Unit_Price' exist and are numeric\n",
    "if 'Order_Quantity' in df.columns and 'Unit_Price' in df.columns:\n",
    "    df['revenue'] = df['Order_Quantity'] * df['Unit_Price']\n",
    "else:\n",
    "    raise ValueError(\"Missing 'Order_Quantity' or 'Unit_Price' columns for revenue calculation\")\n",
    "\n",
    "total_revenue = df['revenue'].sum()\n",
    "print(f\"Total Revenue: ${total_revenue:.2f}\")\n",
    "\n",
    "if 'Product' in df.columns:\n",
    "    best_sellers = df.groupby('Product')['revenue'].sum().sort_values(ascending=False)\n",
    "    print(\"Top 10 Best Selling Products:\\n\" + str(best_sellers.head(10))) # by default it is 5.\n",
    "else:\n",
    "    raise ValueError(\"Missing 'Product' column for best-selling products analysis\")\n",
    "\n",
    "daily_series = df.groupby('Date')['revenue'].sum().mean()\n",
    "print(f\"Average daily sales revenue: ${daily_series:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
